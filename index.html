<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SXZZ1ZXKKD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SXZZ1ZXKKD');
</script>

  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15.5px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 23px;
    }
    heading2 {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14.5px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }

    h1{text-align: right;}
  </style>
  <link rel="icon" type="image/png" href="./public/wave.png">
  <title>Shoukang Hu</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
  <tr><td>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td width="67%" valign="middle">
  <p align="center">
  <name>Shoukang Hu</name>
  </p><p>
    <font style="line-height:1.2;">I am currently a Research Fellow at <a href="https://www.mmlab-ntu.com/index.html">MMLab@NTU</a>, Nanyang Technological University, working with <a href="https://liuziwei7.github.io">Prof. Ziwei Liu</a>. <br>
    <br>
    Prior to that, I obtained the Ph.D. degree in The Chinese Univeristy of Hong Kong under the supervision of <a href="https://www1.se.cuhk.edu.hk/~xyliu/">Prof. Xunying Liu</a>,
    and the B.Eng. Degree in Mechanical and Electrical Engineering from University of Electronic Science and Technology of China in 2017. </font><br>
    <br>
    <font style="line-height:1.5;"><b>Email:</b> shoukang [dot] hu [at] gmail.com</font> 
   </p><p>
  </p><p align=center>
  <a href="https://scholar.google.com/citations?user=9cUPotAAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
  <a href="https://github.com/skhu101">GitHub</a> &nbsp|&nbsp
  <a href="https://drive.google.com/file/d/17hfXV3UncRHtMh8GgkUjR9ATPv_NNpMW/view?usp=share_link">CV</a>
  </p></td>
  <td width="33%">
  <img src="public/me.png"> <!-- should be 280x280 -->
  </td></tr></table>

  <!-- RESEARCH SECTION -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Research</heading> <p>
    Currently, I am interested in exploring multiple modalities to enhance the advancement of perception, reconstruction, and generation, including 3D Human, Automatic Speech Recognition and Automated Machine Learning, i.e.,</p>
    <ul><li><font style="line-height:1.5;"><strong>3D Human/Object Reconstruction/Generation</strong></font> <ul><li><font style="line-height:1.5;">[<a href="https://skhu101.github.io/HumanLiff" target="_blank" rel="noopener noreferrer">HumanLiff</a>] [<a href="https://skhu101.github.io/SHERF" target="_blank" rel="noopener noreferrer">SHERF</a>] [<a href="https://skhu101.github.io/ConsistentNeRF" target="_blank" rel="noopener noreferrer">ConsistentNeRF</a>]</font></li></ul> 
    <li><font style="line-height:1.5;"><strong>Automatic Speech Recognition (ASR)</strong></font> <ul><li><font style="line-height:1.5;">[<a href="https://arxiv.org/abs/2012.04494" target="_blank" rel="noopener noreferrer">Bayesian LF-MMI ASR</a>] [<a href="https://arxiv.org/abs/2201.03943" target="_blank" rel="noopener noreferrer">NAS LF-MMI ASR</a>] [<a href="https://speechsystemdemo.github.io/demo/M14B2M3.html" target="_blank" rel="noopener noreferrer">CUHK Dysarthric ASR</a>]</font></li></ul> 
    <li><font style="line-height:1.5;"><strong>Automated Machine Learning (AutoML)</strong></font> <ul><li><font style="line-height:1.5;">[<a href="https://github.com/SNAS-Series/SNAS-Series" target="_blank" rel="noopener noreferrer">SNAS-Series</a>] [<a href="https://arxiv.org/abs/2203.15207" target="_blank" rel="noopener noreferrer">Supernet Splitting</a>]</font></li></ul></li></ul>
    </p>
  </td> </tr> </table>

  <!-- NEWS SECTION -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr> <td width="100%" valign="middle">
    <heading>News</heading> <p>
      <ul>
        <li><font style="line-height:1.5;">[Aug. 2023] SHERF code has been release.</font></li>
        <li><font style="line-height:1.5;">[Jul. 2023] Our SHERF paper is accepted by ICCV2023.</font></li>
        <li><font style="line-height:1.5;">[Jun. 2022] I joined MMLab@NTU to start a new journey!</font></li>
      </ul>
    </p> </td> </tr> </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


  <!-- Conference Papers SECTION -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr> <td width="100%" valign="middle">
    <heading>Conference Papers</heading> <p>
    </p> </td> </tr> </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

  <!--
  <tr> <td width="25%">
  <heading2><i>Current Projects</i></heading2>
  </td/> </tr>
  -->
  <p style="color:red">* denotes equal contribution</p>
    <!-- project begin -->
    <tr onmouseout="aso_stop()" onmouseover="aso_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
         <img src='./public/ICCV2023_SHERF.png' width="180">
        </div>
        <script type="text/javascript">
          function aso_start() {
            document.getElementById('aso_image').style.opacity = "1";
          }

          function aso_stop() {
            document.getElementById('aso_image').style.opacity = "0";
          }
          aso_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>SHERF: Generalizable Human NeRF from a Single Image</papertitle></a><br>
<!-- authors -->
<strong>Shoukang Hu*</strong>,
<a href="https://hongfz16.github.io/">Fangzhou Hong*</a>,
<a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ">Liang Pan</a>,
Haiyi Mei,
<a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en">Lei Yang</a>,
<a href="https://liuziwei7.github.io/">Ziwei Liu</a><br>
<!-- publication status and links -->
In International Conference on Computer Vision (ICCV), 2023.<br>
[<a href="https://arxiv.org/abs/2303.12791">Pdf</a>] [<a href="https://skhu101.github.io/SHERF/">Project Page</a>] [<a href="https://github.com/skhu101/SHERF">code</a>]
<p></p>
<!-- project description -->
<i><font color="#FF7F50">SHERF learns a <strong>Generalizable Human NeRF</strong> to animate 3D humans from a single image.</font></i>
</td></tr>
<!-- project end -->

    <!-- project begin -->
      <tr onmouseout="aso_stop()" onmouseover="aso_start()">
             <td style="padding:20px;width:25%;vertical-align:middle">
               <div class="one">
                <img src='./public/ICLR2022_GM_NAS_thumbnail.gif' width="180">
               </div>
               <script type="text/javascript">
                 function aso_start() {
                   document.getElementById('aso_image').style.opacity = "1";
                 }

                 function aso_stop() {
                   document.getElementById('aso_image').style.opacity = "0";
                 }
                 aso_stop()
               </script>
             </td>
             <td style="padding:20px;width:75%;vertical-align:text-top">
    <!-- title -->
    <papertitle>Generalizing Few-Shot NAS with Gradient Matching</papertitle></a><br>
    <!-- authors -->
    <strong>Shoukang Hu*</strong>,
    <a href="https://ruocwang.github.io">Ruocheng Wang*</a>,
    <a href="https://scholar.google.com/citations?user=2p7x6OUAAAAJ&hl=en&oi=ao">Lanqing Hong</a>,
    <a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ&hl=en">Zhenguo Li</a>,
    <a href="http://web.cs.ucla.edu/~chohsieh/">Cho-Jui Hsieh</a>,
    <a href="https://sites.google.com/site/jshfeng/">Jiashi Feng</a><br>
    <!-- publication status and links -->
    In International Conference on Learning Representations (ICLR), 2022.<br>
    [<a href="https://arxiv.org/abs/2203.15207">Pdf</a>] [<a href="https://github.com/skhu101/GM-NAS">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/491512114">Zhihu</a>]
    <p></p>
    <!-- project description -->
    <i><font color="#FF7F50">We propose a novel Gradient Matching NAS (GM-NAS) - <strong>a generalized supernet splitting schema</strong> that utilizes <strong>gradient matching score</strong> as the splitting criterion and formulates supernet partitioning as <strong>a graph clustering problem</strong>.</font></i>
    </td></tr>
<!-- project end -->

  <!-- project begin -->
    <tr onmouseout="fish_stop()" onmouseover="fish_start()">
           <td style="padding:20px;width:25%;vertical-align:middle">
             <div class="one">
               <img src='./public/TASLP_NAS_bottleneck_dim_search_space.png' width="180">
             </div>
             <script type="text/javascript">
               function fish_start() {
                 document.getElementById('fish_image').style.opacity = "1";
               }

               function fish_stop() {
                 document.getElementById('fish_image').style.opacity = "0";
               }
               fish_stop()
             </script>
           </td>
           <td style="padding:20px;width:75%;vertical-align:text-top">
    <!-- title -->
    <papertitle>Neural Architecture Search For LF-MMI Trained Time Delay Neural Networks</papertitle><br>
    <!-- authors -->
    <strong>Shoukang Hu</strong>,
    <a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
    <a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
    <a href="https://scholar.google.com/citations?user=tONFEQcAAAAJ&hl=en">Mingyu Cui</a>,
    <a href="https://scholar.google.com/citations?user=RS59rgIAAAAJ&hl=en">Mengzhe Geng</a>,
    <a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
    <a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
    <!-- publication status and links -->
    In International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021.<br>
    [<a href="https://arxiv.org/abs/2007.08818">Pdf</a>] [<a href="https://github.com/skhu101/TDNN-F_NAS">Code</a>]
    <p></p>
    <!-- project description -->
    </td></tr>
<!-- project end -->

  <!-- project begin -->
  <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
    <td width="25%">
      <div class="one">
        <img src='./public/AISTATS2021_cost_gradient.gif' width="160"> <!-- should be 160x160 -->
      </div>
      <script type="text/javascript">
        function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
        }

        function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
      </script>
    </td>
    <!-- <td valign="middle" width="75%"> -->
      <td style="padding:20px;width:75%;vertical-align:middle">
      <!-- title -->
      <papertitle>Understanding the wiring evolution in differentiable neural architecture search</papertitle><br>
      <!-- authors -->
      <a href="https://siruixie.com">Sirui Xie*</a>,
      <strong>Shoukang Hu*</strong>,
      <a href="https://scholar.google.com/citations?user=q4lnWaoAAAAJ&hl=en">Xinjiang Wang</a>,
      <a href="https://scholar.google.com/citations?user=4m061tYAAAAJ&hl=en">Chunxiao Liu</a>,
      <a href="https://shijianping.me">Jianping Shi</a>,
      <a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
      <a href="http://dahua.me">Dahua Lin</a><br>
      <!-- publication status and links -->
      In International Conference on Artificial Intelligence and Statistics (AISTATS), 2021.<br>
      [<a href="https://arxiv.org/abs/2009.01272">Pdf</a>] [<a href="https://github.com/SNAS-Series/SNAS-Series">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/357037023">Zhihu</a>]
      <p></p>
      <!-- project description -->

    </td></tr>
  <!-- project end -->

  <!-- project begin -->
<tr><td width="25%"><div class="one">
<!-- project symbol -->
<img src="./public/CVPR2020_DSNAS_backward_slides_dsnas.gif" width="160"> <!-- should be 160x160 -->
</div></td>
<!-- <td valign="top" width="75%"> -->
<td style="padding:20px;width:75%;vertical-align:middle">
<!-- title -->
<papertitle>DSNAS: Direct Neural Architecture Search without Parameter Retraining</papertitle></a><br>
<!-- authors -->
<strong>Shoukang Hu*</strong>,
<a href="https://siruixie.com">Sirui Xie*</a>,
<a href="https://scholar.google.com/citations?user=qTMA5BQAAAAJ&hl=en">Hehui Zheng</a>,
<a href="https://scholar.google.com/citations?user=4m061tYAAAAJ&hl=en">Chunxiao Liu</a>,
<a href="https://shijianping.me">Jianping Shi</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="http://dahua.me">Dahua Lin</a><br>
<!-- publication status and links -->
In Conference on Computer Vision and Pattern Recognition (CVPR), 2020.<br>
[<a href="https://arxiv.org/abs/2002.09128">Pdf</a>] [<a href="https://github.com/SNAS-Series/SNAS-Series">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/141884849">Zhihu</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->

  <!-- project begin -->
  <tr onmouseout="fish_stop()" onmouseover="fish_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='./public/TASLP_Bayes_tdnn.png' width="160">
      </div>
      <script type="text/javascript">
        function fish_start() {
          document.getElementById('fish_image').style.opacity = "1";
        }

        function fish_stop() {
          document.getElementById('fish_image').style.opacity = "0";
        }
        fish_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>LF-MMI Training of Bayesian and Gaussian Process Time Delay Neural Networks for Speech Recognition</papertitle><br>
<!-- authors -->
<strong>Shoukang Hu</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<a href="https://scholar.google.com.hk/citations?user=R0E0bKkAAAAJ&hl=en">Max W. Y. Lam</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="http://mi.eng.cam.ac.uk/~xw369/">Xixin Wu</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In INTERSPEECH 2019.<br>
[<a href="https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2379.pdf">Pdf</a>] [<a href="https://github.com/skhu101/Bayesian_TDNN.git">Code</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->

  <!-- project begin -->
  <tr onmouseout="fish_stop()" onmouseover="fish_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='./public/INTERSPEECH2019_pitch.png' width="160">
      </div>
      <script type="text/javascript">
        function fish_start() {
          document.getElementById('fish_image').style.opacity = "1";
        }

        function fish_stop() {
          document.getElementById('fish_image').style.opacity = "0";
        }
        fish_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>On the Use of Pitch Features for Disordered Speech Recognition</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu*</a>,
<strong>Shoukang Hu*</strong>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In INTERSPEECH 2019.<br>
[<a href="https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2609.pdf">Pdf</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->

  <!-- project begin -->
  <tr onmouseout="fish_stop()" onmouseover="fish_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='./public/ICASSP2019_GPLSTM.png' width="160">
      </div>
      <script type="text/javascript">
        function fish_start() {
          document.getElementById('fish_image').style.opacity = "1";
        }

        function fish_stop() {
          document.getElementById('fish_image').style.opacity = "0";
        }
        fish_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Bayesian and Gaussian Process Neural Networks for Large Vocabulary Continuous Speech Recognition</papertitle><br>
<!-- authors -->
<strong>Shoukang Hu</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://scholar.google.com.hk/citations?user=R0E0bKkAAAAJ&hl=en">Max W. Y. Lam</a>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="http://mi.eng.cam.ac.uk/~xw369/">Xixin Wu</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019.<br>
[<a href="https://ieeexplore.ieee.org/document/8682487">Pdf</a>] [<a href="https://github.com/skhu101/Bayesian_TDNN.git">Code</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/INTERSPEECH 2018_GPNN_architecture.png' width="160">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Gaussian Process Neural Networks for Speech Recognition</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com.hk/citations?user=R0E0bKkAAAAJ&hl=en">Max W. Y. Lam*</a>,
<strong>Shoukang Hu*</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://dblp.org/pid/139/5460.html">Rongfeng Su</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In INTERSPEECH 2018.<br>
[<a href="https://www.isca-speech.org/archive/pdfs/interspeech_2018/lam18_interspeech.pdf">Pdf</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/ICASSP2019_BLHUC.jpg' width="180">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>BLHUC: Bayesian learning of hidden unit contributions for deep neural network speaker adaptation</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="http://www.ee.cuhk.edu.hk/~tanlee/">Tan Lee</a>,
<strong>Shoukang Hu</strong>,
<a href="https://www.researchgate.net/profile/Lan-Wang-58">Lan Wang</a><br>
<!-- publication status and links -->
In International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019. <a href="https://www.2019.ieeeicassp.org/2019.ieeeicassp.org/program.html#awards" style="color:red">Best Student Paper Award </a> <br>
[<a href="https://ieeexplore.ieee.org/document/8682667">Pdf</a>] [<a href="https://github.com/XIEXurong/kaldi_bayes_adapt">Code</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/INTERSPEECH 2019_AVSR_gating.jpg' width="160">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<strong>Shoukang Hu</strong>,
Yi Wang,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://dblp.org/pid/139/5460.html">Rongfeng Su</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In INTERSPEECH 2019. <a style="color:red">Best Student Paper Award Nomination </a> <br>
[<a href="https://www.isca-speech.org/archive/interspeech_2019/liu19j_interspeech.html">Pdf</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->


</table>
<!-- end of Conference Paper section -->


<!-- Journal Papers SECTION -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Journal Papers</heading> <p>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<p style="color:red">* denotes equal contribution</p>
<!--
<tr> <td width="25%">
<heading2><i>Current Projects</i></heading2>
</td/> </tr>
-->

  <!-- project begin -->
  <tr onmouseout="fish_stop()" onmouseover="fish_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='./public/TASLP_NAS_context_search_space.png' width="180">
      </div>
      <script type="text/javascript">
        function fish_start() {
          document.getElementById('fish_image').style.opacity = "1";
        }

        function fish_stop() {
          document.getElementById('fish_image').style.opacity = "0";
        }
        fish_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Neural Architecture Search For LF-MMI Trained Time Delay Neural Networks</papertitle><br>
<!-- authors -->
<strong>Shoukang Hu</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://scholar.google.com/citations?user=tONFEQcAAAAJ&hl=en">Mingyu Cui*</a>,
<a href="https://www.researchgate.net/profile/Jiajun-Deng-4">Jiajun Deng*</a>,
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://scholar.google.com/citations?user=RS59rgIAAAAJ&hl=en">Mengzhe Geng</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP).<br>
[<a href="https://arxiv.org/abs/2201.03943">Pdf</a>] [<a href="https://github.com/skhu101/TDNN-F_NAS">Code</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->

<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/TASLP_CUHK Dysarthric Speech_manual_arch.png' width="180">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Recent Progress in the CUHK Dysarthric Speech Recognition System</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu*</a>,
<a href="https://scholar.google.com/citations?user=RS59rgIAAAAJ&hl=en">Mengzhe Geng*</a>,
<strong>Shoukang Hu*</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie*</a>,
<a href="https://scholar.google.com/citations?user=tONFEQcAAAAJ&hl=en">Mingyu Cui</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP).<br>
[<a href="https://ieeexplore.ieee.org/document/9463679">Pdf</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/TASLP_Bayes_tdnn.png' width="160">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Bayesian Learning of LF-MMI Trained Time Delay Neural Networks for Speech Recognition</papertitle><br>
<!-- authors -->
<strong>Shoukang Hu</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://www.researchgate.net/profile/Zi-Ye-12">Zi Ye</a>,
<a href="https://scholar.google.com/citations?user=RS59rgIAAAAJ&hl=en">Mengzhe Geng</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
In IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP).<br>
[<a href="https://arxiv.org/abs/2012.04494">Pdf</a>] [<a href="https://github.com/skhu101/Bayesian_TDNN.git">Code</a>]
<p></p>
<!-- project description -->
</td></tr>
<!-- project end -->

</table>
<!-- end of Journal Papers section -->


<!-- Demo SECTION -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Demo</heading> <p>
    <ul>
      The CUHK Dysarthric Speech Recognition Systems for English and Cantonese, INTERSPEECH 2019 Show & Tell
      [<a href="https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/8047.pdf">Pdf</a>]
      [<a href="https://speechsystemdemo.github.io/demo/M14B2M3.html">Demo</a>]
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


<!-- Services SECTION -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Services</heading> <p>
    <ul>
      <li><font style="line-height:1.5;">Conference PC Member: ICASSP 22-23, INTERSPEECH 21-23, NeurIPS 22, ICML 22-23, AAAI 22-23, IJCAI 23, AISTATS 21, SIGGRAPH 23</font></li>
      <li><font style="line-height:1.5;">Journal Reviewer: TASLP, Computer Speech & Language, TPAMI, IJCV, TNNLS, Neural Networks </font></li>
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

<!-- Selected Rewards SECTION -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Selected Rewards</heading> <p>
    <ul>
      <li><font style="line-height:1.5;"><b>ISCA Yajie Miao Memorial Grant Winner</b></font></li>
      <li><font style="line-height:1.5;"><b>CUHK Postgraduate Student Scholarship</b></font></li>
      <li><font style="line-height:1.5;"><b>National Scholarship</b> awarded by the Ministry of Education of China in 2015 & 2016</font></li>
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


<!-- Working Experience SECTION -->
<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Working Experience</heading> <p>
    <ul>
      <li><font style="line-height:1.5;">Visiting Student at SIAT, Chinese Academy of Sciences (Dec. 2016 - May. 2017)</font> </li>
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"> -->
<!-- end of Working Experience section -->


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td> <br>
  <p align="right"> <font size="2">
  <a href="https://jonbarron.info/">Good artists copy.</a>
	</font> </p> </td> </tr> </table>
    </td>
    </tr>
  </table>
  <p align="center">
    <!-- <a href='https://clustrmaps.com/site/1bmo5'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=400&t=m&d=l0ikMMOAMQeGt-AX7UvLWbfa5Seb3qC7MS83aFnqxws'/></a> -->
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=m&d=l0ikMMOAMQeGt-AX7UvLWbfa5Seb3qC7MS83aFnqxws&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script>
    </p>
    </td>
    </tr>
    </table>



</body>
</html>
