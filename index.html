<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SXZZ1ZXKKD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SXZZ1ZXKKD');
</script>

  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15.5px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15.5px;
    }
    institute {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15.5px;
    font-weight: 590
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 23px;
    }
    heading2 {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }

    h1{text-align: right;}
  </style>
  <link rel="icon" type="image/png" href="./public/wave.png">
  <title>Shoukang Hu</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
  <tr><td>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td width="67%" valign="middle">
  <p align="center">
  <name>Shoukang Hu</name>
  </p>
  <p style="text-align:justify">
    <font style="line-height:1.4;">I am currently a Research Scientist at <institute>Sony AI</institute>. 
    Prior to that, I was a Research Fellow at MMLab@NTU, working with <a href="https://liuziwei7.github.io">Prof. Ziwei Liu</a>. 
    I obtained the Ph.D. degree in The Chinese Univeristy of Hong Kong under the supervision of <a href="https://www1.se.cuhk.edu.hk/~xyliu/">Prof. Xunying Liu</a>,
    and the B.Eng. Degree in Mechanical and Electrical Engineering from University of Electronic Science and Technology of China. </font><br>
    <br>
    <font style="line-height:1.5;"><b>Email:</b> shoukang [dot] hu [at] gmail.com</font> 
   </p><p>
  </p><p align=center>
  <a href="https://scholar.google.com/citations?user=9cUPotAAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
  <a href="https://github.com/skhu101">GitHub</a> &nbsp|&nbsp
  <a href="https://drive.google.com/file/d/10k14L0ndRbuHndKkum3uD2UpoNRZT82R/view?usp=sharing">CV</a>
  </p></td>
  <td width="33%">
  <img src="public/me.png"> <!-- should be 280x280 -->
  </td></tr></table>

  <!-- RESEARCH SECTION -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Research Interests</heading> 
  <p style="text-align:justify">
    Currently, I am interested in exploring multiple modalities to enhance the advancement of perception, reconstruction, and generation, including 3D Human, Automatic Speech Recognition and Automated Machine Learning, i.e.,</p>
    <ul><li><font style="line-height:1.5;"><strong>3D Human/Object Reconstruction/Generation</strong></font> <ul><li><font style="line-height:1.5;">[<a href="https://skhu101.github.io/GauHuman" target="_blank" rel="noopener noreferrer">GauHuman</a>] [<a href="https://skhu101.github.io/HumanLiff" target="_blank" rel="noopener noreferrer">HumanLiff</a>] [<a href="https://skhu101.github.io/SHERF" target="_blank" rel="noopener noreferrer">SHERF</a>] [<a href="https://skhu101.github.io/ConsistentNeRF" target="_blank" rel="noopener noreferrer">ConsistentNeRF</a>]</font></li></ul> 
    <li><font style="line-height:1.5;"><strong>Automatic Speech Recognition (ASR)</strong></font> <ul><li><font style="line-height:1.5;">[<a href="https://arxiv.org/abs/2012.04494" target="_blank" rel="noopener noreferrer">Bayesian LF-MMI ASR</a>] [<a href="https://arxiv.org/abs/2201.03943" target="_blank" rel="noopener noreferrer">NAS LF-MMI ASR</a>] [<a href="https://speechsystemdemo.github.io/demo/M14B2M3.html" target="_blank" rel="noopener noreferrer">CUHK Dysarthric ASR</a>]</font></li></ul> 
    <li><font style="line-height:1.5;"><strong>Automated Machine Learning (AutoML)</strong></font> <ul><li><font style="line-height:1.5;">[<a href="https://github.com/SNAS-Series/SNAS-Series" target="_blank" rel="noopener noreferrer">Efficient NAS Algorithm</a>] [<a href="https://arxiv.org/abs/2203.15207" target="_blank" rel="noopener noreferrer">Accurate NAS Performance Estimation</a>]</font></li></ul></li></ul>
  </p>
  </td> </tr> </table>

  <!-- NEWS SECTION -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr> <td width="100%" valign="middle">
    <heading>News</heading> <p>
      <ul>
        <li><font style="line-height:1.5;">[Mar. 2024] I joined Sony AI to start a new journey!</font></li>
        <!-- <li><font style="line-height:1.5;">[Feb. 2024] Our GauHuman paper is accepted by CVPR2024.</font></li>
        <li><font style="line-height:1.5;">[Dec. 2023] We have released the code of GauHuman.</font></li>
        <li><font style="line-height:1.5;">[Aug. 2023] SHERF code has been released.</font></li>
        <li><font style="line-height:1.5;">[Jul. 2023] Our SHERF paper is accepted by ICCV2023.</font></li>
        <li><font style="line-height:1.5;">[Jun. 2022] I joined MMLab@NTU to start a new journey!</font></li> -->
      </ul>
    </p> </td> </tr> </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


  <!-- Research SECTION -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr> <td width="100%" valign="middle">
    <heading>Research</heading> <p>
    </p> </td> </tr> </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

  <!--
  <tr> <td width="25%">
  <heading2><i>Current Projects</i></heading2>
  </td/> </tr>
  -->
  <p style="color:red">* denotes equal contribution</p>


    <!-- project begin -->
    <tr onmouseout="aso_stop()" onmouseover="aso_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
        <img src='./public/GauHuman_thumbnail.gif' width="180">
        </div>
        <script type="text/javascript">
          function aso_start() {
            document.getElementById('aso_image').style.opacity = "1";
          }

          function aso_stop() {
            document.getElementById('aso_image').style.opacity = "0";
          }
          aso_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:text-top">
    <!-- title -->
    <papertitle>GauHuman: Articulated Gaussian Splatting from Monocular Human Videos</papertitle></a><br>
    <!-- authors -->
    <strong>Shoukang Hu</strong>,
    <a href="https://liuziwei7.github.io/" target="_blank">Ziwei Liu</a><br>
    <!-- publication status and links -->
    Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024.<br>
    [<a href="https://arxiv.org/pdf/2312.02973.pdf">Paper</a>] [<a href="https://skhu101.github.io/GauHuman/">Project Page</a>] [<a href="https://github.com/skhu101/GauHuman">Code</a>] <img src="https://img.shields.io/github/stars/skhu101/GauHuman?style=social"> <img src="https://img.shields.io/github/forks/skhu101/GauHuman?style=social">
    <p></p>
    <!-- project description -->
    <i><font color="#FF7F50"> GauHuman learns articulated Gaussian Splatting from monocular videos with both <strong>fast training</strong> (1~2 minutes) and <strong>real-time rendering</strong> (up to 189 FPS).</font></i>
    </td></tr>
    <!-- project end -->


    <!-- project begin -->
    <tr onmouseout="aso_stop()" onmouseover="aso_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
        <img src='./public/HumanLiff_thumbnail.gif' width="180">
        </div>
        <script type="text/javascript">
          function aso_start() {
            document.getElementById('aso_image').style.opacity = "1";
          }

          function aso_stop() {
            document.getElementById('aso_image').style.opacity = "0";
          }
          aso_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:text-top">
    <!-- title -->
    <papertitle>HumanLiff: Layer-wise 3D Human Generation with Diffusion Model</papertitle></a><br>
    <!-- authors -->
    <strong>Shoukang Hu</strong>,
    <a href="https://hongfz16.github.io/" target="_blank">Fangzhou Hong</a>,
    <a href="https://www.cs.umd.edu/~taohu/" target="_blank">Tao Hu</a>,
    <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ" target="_blank">Liang Pan</a>,
    Weiye Xiao,
    Haiyi Mei,
    <a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en" target="_blank">Lei Yang</a>,
    <a href="https://liuziwei7.github.io/" target="_blank">Ziwei Liu</a><br>
    <!-- publication status and links -->
    Preprint<br>
    [<a href="https://arxiv.org/abs/2308.09712">Paper</a>] [<a href="https://skhu101.github.io/HumanLiff/">Project Page</a>] [<a href="https://github.com/skhu101/HumanLiff">Code</a>] <img src="https://img.shields.io/github/stars/skhu101/HumanLiff?style=social"> <img src="https://img.shields.io/github/forks/skhu101/HumanLiff?style=social">
    <p></p>
    <!-- project description -->
    <i><font color="#FF7F50"> HumanLiff learns the layer-wise 3D human generative model with a unified diffusion process.</font></i>
    </td></tr>
    <!-- project end -->


    <!-- project begin -->
    <tr onmouseout="aso_stop()" onmouseover="aso_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
        <img src='./public/ConsistentNeRF_thumbnail.gif' width="180" height="90">
        </div>
        <script type="text/javascript">
          function aso_start() {
            document.getElementById('aso_image').style.opacity = "1";
          }

          function aso_stop() {
            document.getElementById('aso_image').style.opacity = "0";
          }
          aso_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:text-top">
    <!-- title -->
    <papertitle>ConsistentNeRF: Enhancing Neural Radiance Fields with 3D Consistency for Sparse View Synthesis</papertitle></a><br>
    <!-- authors -->
    <strong>Shoukang Hu</strong>,
    <a href="https://www.cs.ox.ac.uk/people/kaichen.zhou/" target="_blank">Kaichen Zhou</a>,
    <a target="_blank">Kaiyu Li</a>,
    <a href="https://yulonghui.github.io/" target="_blank">Longhui Yu</a>,
    <a href="https://scholar.google.com.sg/citations?user=2p7x6OUAAAAJ&hl=en" target="_blank">Lanqing Hong</a>,
    <a href="https://scholar.google.com/citations?user=mlA_3r0AAAAJ&hl=en" target="_blank">Tianyang Hu</a>,
    <a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ&hl=en" target="_blank">Zhenguo	Li</a>,
    <a href="https://www.comp.nus.edu.sg/~leegh/" target="_blank">Gim Hee	Lee</a>,
    <a href="https://liuziwei7.github.io/" target="_blank">Ziwei Liu</a><br>
    <!-- publication status and links -->
    Preprint<br>
    [<a href="https://arxiv.org/pdf/2305.11031.pdf">Paper</a>] [<a href="https://skhu101.github.io/ConsistentNeRF/">Project Page</a>] [<a href="https://github.com/skhu101/ConsistentNeRF">Code</a>] <img src="https://img.shields.io/github/stars/skhu101/ConsistentNeRF?style=social"> <img src="https://img.shields.io/github/forks/skhu101/ConsistentNeRF?style=social">
    <p></p>
    <!-- project description -->
    <i><font color="#FF7F50"> ConsistentNeRF Enhances Neural Radiance Fields with 3D Consistency for Sparse View Synthesis.</font></i>
    </td></tr>
    <!-- project end -->

    <!-- project begin -->
    <tr onmouseout="aso_stop()" onmouseover="aso_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
         <img src='./public/ICCV2023_SHERF.png' width="180">
        </div>
        <script type="text/javascript">
          function aso_start() {
            document.getElementById('aso_image').style.opacity = "1";
          }

          function aso_stop() {
            document.getElementById('aso_image').style.opacity = "0";
          }
          aso_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>SHERF: Generalizable Human NeRF from a Single Image</papertitle></a><br>
<!-- authors -->
<strong>Shoukang Hu*</strong>,
<a href="https://hongfz16.github.io/">Fangzhou Hong*</a>,
<a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ">Liang Pan</a>,
Haiyi Mei,
<a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en">Lei Yang</a>,
<a href="https://liuziwei7.github.io/">Ziwei Liu</a><br>
<!-- publication status and links -->
International Conference on Computer Vision (<strong>ICCV</strong>), 2023.<br>
[<a href="https://arxiv.org/abs/2303.12791">Paper</a>] [<a href="https://skhu101.github.io/SHERF/">Project Page</a>] [<a href="https://github.com/skhu101/SHERF">code</a>] <img src="https://img.shields.io/github/stars/skhu101/SHERF?style=social"> <img src="https://img.shields.io/github/forks/skhu101/SHERF?style=social">
<p></p>
<!-- project description -->
<i><font color="#FF7F50">SHERF learns a <strong>Generalizable Human NeRF</strong> to animate 3D humans from a single image.</font></i>
</td></tr>
<!-- project end -->


<!-- project begin -->
  <tr onmouseout="aso_stop()" onmouseover="aso_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
            <img src='./public/ICLR2022_GM_NAS_thumbnail.gif' width="180">
            </div>
            <script type="text/javascript">
              function aso_start() {
                document.getElementById('aso_image').style.opacity = "1";
              }

              function aso_stop() {
                document.getElementById('aso_image').style.opacity = "0";
              }
              aso_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:text-top">
    <!-- title -->
    <papertitle>Generalizing Few-Shot NAS with Gradient Matching</papertitle></a><br>
    <!-- authors -->
    <strong>Shoukang Hu*</strong>,
    <a href="https://ruocwang.github.io">Ruocheng Wang*</a>,
    <a href="https://scholar.google.com/citations?user=2p7x6OUAAAAJ&hl=en&oi=ao">Lanqing Hong</a>,
    <a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ&hl=en">Zhenguo Li</a>,
    <a href="http://web.cs.ucla.edu/~chohsieh/">Cho-Jui Hsieh</a>,
    <a href="https://sites.google.com/site/jshfeng/">Jiashi Feng</a><br>
    <!-- publication status and links -->
    International Conference on Learning Representations (<strong>ICLR</strong>), 2022.<br>
    [<a href="https://arxiv.org/abs/2203.15207">Paper</a>] [<a href="https://github.com/skhu101/GM-NAS">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/491512114">Zhihu</a>] <img src="https://img.shields.io/github/stars/skhu101/GM-NAS?style=social"> <img src="https://img.shields.io/github/forks/skhu101/GM-NAS?style=social">
    <p></p>
    <!-- project description -->
    <i><font color="#FF7F50"> GM-NAS formulates supernet partitioning as <strong>a graph clustering problem</strong> and utilizes <strong>gradient matching score</strong> as the splitting criterion. Notably, we achieve <strong>80.6%</strong> accuracy on ImageNet under 600 flops constraint.</font></i>
  </td></tr>
<!-- project end -->


<!-- project begin -->
  <tr onmouseout="fish_stop()" onmouseover="fish_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='./public/TASLP_NAS_bottleneck_dim_search_space.png' width="180">
      </div>
      <script type="text/javascript">
        function fish_start() {
          document.getElementById('fish_image').style.opacity = "1";
        }

        function fish_stop() {
          document.getElementById('fish_image').style.opacity = "0";
        }
        fish_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:text-top">
    <!-- title -->
    <papertitle>Neural Architecture Search For LF-MMI Trained Time Delay Neural Networks</papertitle><br>
    <!-- authors -->
    <strong>Shoukang Hu</strong>,
    <a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
    <a href="https://scholar.google.com/citations?user=tONFEQcAAAAJ&hl=en">Mingyu Cui*</a>,
    <a href="https://www.researchgate.net/profile/Jiajun-Deng-4">Jiajun Deng*</a>,
    <a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
    <a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
    <a href="https://scholar.google.com/citations?user=RS59rgIAAAAJ&hl=en">Mengzhe Geng</a>,
    <a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
    <a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
    <!-- publication status and links -->
    International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>), 2021.<br>
    IEEE/ACM Transactions on Audio, Speech, and Language Processing (<strong>TASLP</strong>).<br>
    [<a href="https://arxiv.org/abs/2201.03943">Paper</a>] [<a href="https://github.com/skhu101/TDNN-F_NAS">Code</a>] <img src="https://img.shields.io/github/stars/skhu101/TDNN-F_NAS?style=social"> <img src="https://img.shields.io/github/forks/skhu101/TDNN-F_NAS?style=social">
    <p></p>
<!-- project description -->
<i><font color="#FF7F50"> We achieve <strong>9.9%/11.1%</strong> WER on Hub5'00/Rt03 test sets of 300-Hour Switchboard Task with 10.8M parameters.</font></i>
</td></tr>
<!-- project end -->


<!-- project begin -->
  <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
    <td width="25%">
      <div class="one">
        <img src='./public/AISTATS2021_cost_gradient.gif' width="160"> <!-- should be 160x160 -->
      </div>
      <script type="text/javascript">
        function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
        }

        function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
      </script>
    </td>
    <!-- <td valign="middle" width="75%"> -->
      <td style="padding:20px;width:75%;vertical-align:middle">
      <!-- title -->
      <papertitle>Understanding the wiring evolution in differentiable neural architecture search</papertitle><br>
      <!-- authors -->
      <a href="https://siruixie.com">Sirui Xie*</a>,
      <strong>Shoukang Hu*</strong>,
      <a href="https://scholar.google.com/citations?user=q4lnWaoAAAAJ&hl=en">Xinjiang Wang</a>,
      <a href="https://scholar.google.com/citations?user=4m061tYAAAAJ&hl=en">Chunxiao Liu</a>,
      <a href="https://shijianping.me">Jianping Shi</a>,
      <a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
      <a href="http://dahua.me">Dahua Lin</a><br>
      <!-- publication status and links -->
      International Conference on Artificial Intelligence and Statistics (<strong>AISTATS</strong>), 2021.<br>
      [<a href="https://arxiv.org/abs/2009.01272">Paper</a>] [<a href="https://github.com/SNAS-Series/SNAS-Series">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/357037023">Zhihu</a>] <img src="https://img.shields.io/github/stars/SNAS-Series/SNAS-Series?style=social"> <img src="https://img.shields.io/github/forks/SNAS-Series/SNAS-Series?style=social">
      <p></p>
      <!-- project description -->
      <i><font color="#FF7F50"> Our analysis focuses on three observed searching patterns of differentiable NAS: 1) they search by growing instead of pruning; 2) wider networks are more preferred than deeper ones; 3) no edges are selected in bi-level optimization.</font></i>
    </td></tr>
  <!-- project end -->

  <!-- project begin -->
<tr><td width="25%"><div class="one">
<!-- project symbol -->
<img src="./public/CVPR2020_DSNAS_backward_slides_dsnas.gif" width="160"> <!-- should be 160x160 -->
</div></td>
<!-- <td valign="top" width="75%"> -->
<td style="padding:20px;width:75%;vertical-align:middle">
<!-- title -->
<papertitle>DSNAS: Direct Neural Architecture Search without Parameter Retraining</papertitle></a><br>
<!-- authors -->
<strong>Shoukang Hu*</strong>,
<a href="https://siruixie.com">Sirui Xie*</a>,
<a href="https://scholar.google.com/citations?user=qTMA5BQAAAAJ&hl=en">Hehui Zheng</a>,
<a href="https://scholar.google.com/citations?user=4m061tYAAAAJ&hl=en">Chunxiao Liu</a>,
<a href="https://shijianping.me">Jianping Shi</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="http://dahua.me">Dahua Lin</a><br>
<!-- publication status and links -->
Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020.<br>
[<a href="https://arxiv.org/abs/2002.09128">Paper</a>] [<a href="https://github.com/SNAS-Series/SNAS-Series">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/141884849">Zhihu</a>] <img src="https://img.shields.io/github/stars/SNAS-Series/SNAS-Series?style=social"> <img src="https://img.shields.io/github/forks/SNAS-Series/SNAS-Series?style=social">
<p></p>
<!-- project description -->
<i><font color="#FF7F50"> We propose a new problem definition for NAS, i.e., task-specific end-to-end NAS. Our DSNAS got a final <strong>122</strong> review score.</font></i>
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/TASLP_Bayes_tdnn.png' width="160">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Bayesian Learning of LF-MMI Trained Time Delay Neural Networks for Speech Recognition</papertitle><br>
<!-- authors -->
<strong>Shoukang Hu</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://www.researchgate.net/profile/Zi-Ye-12">Zi Ye</a>,
<a href="https://scholar.google.com/citations?user=RS59rgIAAAAJ&hl=en">Mengzhe Geng</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
International Speech Communication Association (<strong>INTERSPEECH</strong>), 2018.<br>
International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>), 2019.<br>
International Speech Communication Association (<strong>INTERSPEECH</strong>), 2019. <a HREF="https://signalprocessingsociety.org/community-involvement/speech-and-language-processing/newsletter/creation-yajie-miao-memorial-student" style="color:red">ISCA Yajie Miao Memorial Grant Winner </a> <br>
In IEEE/ACM Transactions on Audio, Speech, and Language Processing (<strong>TASLP</strong>).<br>
[<a href="https://arxiv.org/abs/2012.04494">Paper</a>] [<a href="https://github.com/skhu101/Bayesian_TDNN.git">Code</a>] <img src="https://img.shields.io/github/stars/skhu101/Bayesian_TDNN?style=social"> <img src="https://img.shields.io/github/forks/skhu101/Bayesian_TDNN?style=social">
<p></p>
<!-- project description -->
<i><font color="#FF7F50"> We improve generalization ability of LF-MMI ASR with <strong>10.4%/11.8%</strong> WER on Hub5'00/Rt03 test sets of 300-Hour Switchboard task.</font></i>
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/TASLP_CUHK Dysarthric Speech_manual_arch.png' width="180">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Recent Progress in the CUHK Dysarthric Speech Recognition System</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu*</a>,
<a href="https://scholar.google.com/citations?user=RS59rgIAAAAJ&hl=en">Mengzhe Geng*</a>,
<strong>Shoukang Hu*</strong>,
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie*</a>,
<a href="https://scholar.google.com/citations?user=tONFEQcAAAAJ&hl=en">Mingyu Cui</a>,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
IEEE/ACM Transactions on Audio, Speech, and Language Processing (<strong>TASLP</strong>).<br>
[<a href="https://ieeexplore.ieee.org/document/9463679">Paper</a>] [<a href="https://speechsystemdemo.github.io/demo/M14B2M3.html">Demo</a>] [<a href="https://www.isca-archive.org/interspeech_2019/hu19c_interspeech.html">Demo Paper</a>]
<p></p>
<!-- project description -->
<i><font color="#FF7F50"> We report our recent progress in CUHK Dysarthric Speech Recognition System.</font></i>
</td></tr>
<!-- project end -->


  <!-- project begin -->
  <tr onmouseout="fish_stop()" onmouseover="fish_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='./public/INTERSPEECH2019_pitch.png' width="160">
      </div>
      <script type="text/javascript">
        function fish_start() {
          document.getElementById('fish_image').style.opacity = "1";
        }

        function fish_stop() {
          document.getElementById('fish_image').style.opacity = "0";
        }
        fish_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>On the Use of Pitch Features for Disordered Speech Recognition</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu*</a>,
<strong>Shoukang Hu*</strong>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
International Speech Communication Association (<strong>INTERSPEECH</strong>), 2019.<br>
[<a href="https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2609.pdf">Paper</a>] [<a href="https://speechsystemdemo.github.io/demo/M14B2M3.html">Demo</a>] [<a href="https://www.isca-archive.org/interspeech_2019/hu19c_interspeech.html">Demo Paper</a>]
<p></p>
<!-- project description -->
<i><font color="#FF7F50"> We investigate the use of pitch features in Disordered Speech Recognition.</font></i>
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/ICASSP2019_BLHUC.jpg' width="180">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>BLHUC: Bayesian learning of hidden unit contributions for deep neural network speaker adaptation</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com.hk/citations?user=bGD7wa0AAAAJ&hl=zh-CN">Xurong Xie</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="http://www.ee.cuhk.edu.hk/~tanlee/">Tan Lee</a>,
<strong>Shoukang Hu</strong>,
<a href="https://www.researchgate.net/profile/Lan-Wang-58">Lan Wang</a><br>
<!-- publication status and links -->
International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>), 2019. <a href="https://www.2019.ieeeicassp.org/2019.ieeeicassp.org/program.html#awards" style="color:red">Best Student Paper Award </a> <br>
[<a href="https://ieeexplore.ieee.org/document/8682667">Paper</a>] [<a href="https://github.com/XIEXurong/kaldi_bayes_adapt">Code</a>] 
<p></p>
<!-- project description -->
<i><font color="#FF7F50"> BLHUC achieves <strong>9.7%/10.7%</strong> WER on Hub5'00/Rt03 test sets of 300-Hour Switchboard task.</font></i>
</td></tr>
<!-- project end -->


<!-- project begin -->
<tr onmouseout="fish_stop()" onmouseover="fish_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <img src='./public/INTERSPEECH 2019_AVSR_gating.jpg' width="160">
    </div>
    <script type="text/javascript">
      function fish_start() {
        document.getElementById('fish_image').style.opacity = "1";
      }

      function fish_stop() {
        document.getElementById('fish_image').style.opacity = "0";
      }
      fish_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:text-top">
<!-- title -->
<papertitle>Exploiting Visual Features Using Bayesian Gated Neural Networks for Disordered Speech Recognition</papertitle><br>
<!-- authors -->
<a href="https://scholar.google.com/citations?user=ndVYtaUAAAAJ&hl=zh-CN">Shansong Liu</a>,
<strong>Shoukang Hu</strong>,
Yi Wang,
<a href="https://scholar.google.com/citations?user=fY1IJ4wAAAAJ&hl=en">Jianwei Yu</a>,
<a href="https://dblp.org/pid/139/5460.html">Rongfeng Su</a>,
<a href="https://www1.se.cuhk.edu.hk/~xyliu/">Xunying Liu</a>,
<a href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Helen Meng</a><br>
<!-- publication status and links -->
International Speech Communication Association (<strong>INTERSPEECH</strong>), 2019. <a style="color:red">Best Student Paper Award Nomination </a> <br>
[<a href="https://www.isca-speech.org/archive/interspeech_2019/liu19j_interspeech.html">Paper</a>] [<a href="https://speechsystemdemo.github.io/demo/M14B2M3.html">Demo</a>] [<a href="https://www.isca-archive.org/interspeech_2019/hu19c_interspeech.html">Demo Paper</a>]
<p></p>
<!-- project description -->
<i><font color="#FF7F50"> Bayesian Gated Neural Networks achieves <strong>25.7%</strong> WER on UASpeech corpus.</font></i>
</td></tr>
<!-- project end -->

</table>
<!-- end of Paper section -->


<!-- Demo SECTION
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Demo</heading> <p>
    <ul>
      The CUHK Dysarthric Speech Recognition Systems for English and Cantonese, INTERSPEECH 2019 Show & Tell
      [<a href="https://www.isca-archive.org/interspeech_2019/hu19c_interspeech.html">Paper</a>]
      [<a href="https://speechsystemdemo.github.io/demo/M14B2M3.html">Demo</a>]
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"> -->


<!-- Services SECTION -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Services</heading> <p>
    <ul>
      <li><font style="line-height:1.5;">Conference PC Member: ICASSP 22-24, INTERSPEECH 21-23, NeurIPS 22-23, ICML 22-23, AAAI 22-23, IJCAI 23, AISTATS 21, SIGGRAPH 23</font></li>
      <li><font style="line-height:1.5;">Journal Reviewer: TASLP, TPAMI, JMLR, IJCV, TNNLS, Neural Networks </font></li>
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

<!-- Selected Rewards SECTION -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Rewards</heading> <p>
    <ul>
      <!-- <li><font style="line-height:1.5;"><b>ISCA Yajie Miao Memorial Grant Winner</b></font></li> -->
      <li><font style="line-height:1.5;"><b>CUHK Postgraduate Student Scholarship</b></font></li>
      <li><font style="line-height:1.5;"><b>National Scholarship</b> awarded by the Ministry of Education of China in 2015 & 2016</font></li>
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


<!-- Working Experience SECTION -->
<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td width="100%" valign="middle">
  <heading>Working Experience</heading> <p>
    <ul>
      <li><font style="line-height:1.5;">Visiting Student at SIAT, Chinese Academy of Sciences (Dec. 2016 - May. 2017)</font> </li>
    </ul>
  </p> </td> </tr> </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"> -->
<!-- end of Working Experience section -->


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td> <br>
  <p align="right"> <font size="2">
  <a href="https://jonbarron.info/">Good artists copy.</a>
	</font> </p> </td> </tr> </table>
    </td>
    </tr>
  </table>
  <p align="center">
    <!-- <a href='https://clustrmaps.com/site/1bmo5'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=400&t=m&d=l0ikMMOAMQeGt-AX7UvLWbfa5Seb3qC7MS83aFnqxws'/></a> -->
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=m&d=l0ikMMOAMQeGt-AX7UvLWbfa5Seb3qC7MS83aFnqxws&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script>
    </p>
    </td>
    </tr>
    </table>



</body>
</html>